{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV DNN 얼굴검출 : SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     img_id  is_face  confidence      left       top     right    bottom\n",
      "0       0.0      1.0    0.988467  0.825121  0.502939  0.893849  0.658860\n",
      "1       0.0      1.0    0.948228  0.147494  0.511041  0.215415  0.681851\n",
      "2       0.0      1.0    0.945645  0.288223  0.444901  0.359005  0.628938\n",
      "3       0.0      1.0    0.919919  0.499226  0.392553  0.590081  0.570998\n",
      "4       0.0      1.0    0.826739  0.642784  0.463184  0.720662  0.659801\n",
      "..      ...      ...         ...       ...       ...       ...       ...\n",
      "195     0.0      0.0    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "196     0.0      0.0    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "197     0.0      0.0    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "198     0.0      0.0    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "199     0.0      0.0    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# img = cv2.imread('./fig/face/sunglass.png')\n",
    "img = cv2.imread('./fig/face/king_face.png')\n",
    "\n",
    "\n",
    "\n",
    "if img is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "\n",
    "## Caffe model (Single Shot-Multibox Detector)   \n",
    "model = './opencv_face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config = './opencv_face_detector/deploy.prototxt'\n",
    "\n",
    "## tensorflow model   \n",
    "# model = './opencv_face_detector/opencv_face_detector_uint8.pb'\n",
    "# config = './opencv_face_detector/opencv_face_detector.pbtxt'\n",
    "\n",
    "face_net = cv2.dnn.readNet(model, config)\n",
    "# face_net.getLayerNames()\n",
    "\n",
    "if face_net.empty():\n",
    "    print('Net open failed')\n",
    "    sys.exit()\n",
    "\n",
    "# blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                            swapRB=False)\n",
    "\n",
    "face_net.setInput(blob)\n",
    "out = face_net.forward()\n",
    "\n",
    "labels = [\"img_id\", \"is_face\", \"confidence\", \"left\", \"top\", \"right\", \"bottom\"]\n",
    "out_df = pd.DataFrame(out[0][0], columns = labels)\n",
    "print(out_df)\n",
    "\n",
    "detect = out[0, 0, :, :]\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2] # (0, 1, confidence, x1, y1, x2, y2)\n",
    "    \n",
    "    if confidence > 0.15:\n",
    "        # out matrix에서 x1, y1, x2, y2 값이 0 ~1로 normalize 되어 있음\n",
    "        \n",
    "        x1 = int(detect[i, 3]*w)\n",
    "        y1 = int(detect[i, 4]*h)\n",
    "        x2 = int(detect[i, 5]*w)\n",
    "        y2 = int(detect[i, 6]*h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2),\n",
    "                     (0, 0, 255))\n",
    "        \n",
    "        text = 'Face: {}%'.format(round(confidence*100, 2))\n",
    "        cv2.putText(img, text, (x1, y1-1), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV DNN webcam 얼굴검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "## Caffe` 학습모델\n",
    "model = 'opencv_face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config = 'opencv_face_detector/deploy.prototxt'\n",
    "\n",
    "## Tensorflow 학습모델\n",
    "# model = 'opencv_face_detector/opencv_face_detector_uint8.pb'\n",
    "# config = 'opencv_face_detector/opencv_face_detector.pbtxt'\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123))\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()# out.shape=(1,1, 200, 7)\n",
    "    \n",
    "        \n",
    "    detect = out[0, 0, :, :] ##0, 0, 사용안함\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "           \n",
    "            # out matrix에서 x1, y1, x2, y2 값이 0 ~1로 normalize 되어 있음\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "\n",
    "            label = f'Face: {confidence:4.2f}'\n",
    "            cv2.putText(frame, label, (x1, y1 - 1), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo v8 객체검출 with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"C:\\Users\\user\\AppData\\Roaming\\Ultralytics\\settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"D:\\\\OneDrive\\\\Documents\\\\lecture_2019\\\\Academy\\\\27_KOSA\\\\1th_standard\\\\kosa_cv_nlp_rl\\\\2_cv\\\\DL_ML_Opencv\\\\datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"0c445b1c348ff2017d32abd479a34336cf4abf0ea76639b3010e4eeb86a6a47e\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": true,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "## coco dataset\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "print(len(classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./fig/object_detection/vtest.avi\")\n",
    "# cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "# cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"camera open failed\")\n",
    "    sys.exit()\n",
    "\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "# model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov10n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "\n",
    "# with open('./yolov8_pretrained/coco128.txt', 'r') as f:\n",
    "#     data = f.read()\n",
    "#     class_list = data.split('\\n')\n",
    "\n",
    "tm = cv2.TickMeter()\n",
    "\n",
    "while True:\n",
    "    tm.reset()\n",
    "    tm.start()\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('frame read failed')\n",
    "        break\n",
    "    \n",
    "    detection = model(frame, verbose=False)[0]\n",
    "\n",
    "    for data in detection.boxes.data.tolist():\n",
    "        confidence = data[4]\n",
    "        if confidence < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        label = int(data[5])\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, classNames[label]+ ' ' +str(round(confidence, 2))+'%', \n",
    "        (xmin, ymin), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        tm.stop()\n",
    "\n",
    "        total = tm.getTimeMilli()\n",
    "\n",
    "        fps = f'FPS: {1 / total:.4f}'\n",
    "        cv2.putText(frame, fps, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 1)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo v3 객체검출 with opencv dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pjreddie.com/darknet/yolo/\n",
    "\n",
    "# NMSBoxes(bboxes, scores, score_threshold, nms_threshold) -> indices\n",
    "# nms_threshold: nms_threshold a threshold used in non maximum suppression\n",
    "\n",
    "# getPerfProfile() -> retval, timings\n",
    "# .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
    "\n",
    "# https://github.com/pjreddie/darknet/blob/master/data/coco.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 모델 & 설정 파일\n",
    "model = './yolo_v3_pb/yolov3.weights'\n",
    "config = './yolo_v3_pb/yolov3.cfg'\n",
    "class_labels = './yolo_v3_pb/coco.names'\n",
    "\n",
    "# 테스트 이미지 파일\n",
    "img_files = ['../fig/object_detection/dog.jpg', \n",
    "             '../fig/object_detection/person.jpg', \n",
    "             '../fig/object_detection/sheep.jpg', \n",
    "             '../fig/object_detection/kite.jpg']\n",
    "\n",
    "# img_files = ['yolo_v3/fig/peoples.jpg']\n",
    "\n",
    "if img_files is None:\n",
    "    print('Image read failed')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# 네트워크 생성\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 클래스 이름 불러오기\n",
    "classes = []\n",
    "with open(class_labels, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "# colors = np.array([[0, 0, 255], \n",
    "#                    [255, 0, 0],\n",
    "#                    [0, 255, 0],\n",
    "#                    [0, 255, 255],\n",
    "#                    [255, 255, 0],\n",
    "#                    [255, 0, 255]])\n",
    "\n",
    "# 출력 레이어 이름 받아오기\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# outs는 3개의 ndarray 리스트.\n",
    "# output_layers = ['yolo_82', 'yolo_94', 'yolo_106']\n",
    "# output_layers[0].shape = (507, 85), 13*13*3\n",
    "# output_layers[1].shape = (2028, 85), 26*26*3\n",
    "# output_layers[2].shape = (8112, 85), 52*52*3\n",
    "\n",
    "print(output_layers)\n",
    "\n",
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.4\n",
    "\n",
    "# 실행\n",
    "\n",
    "for i in img_files:\n",
    "    img = cv2.imread(i)\n",
    "\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # 블롭 생성 & 추론\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255., (320, 320), swapRB=True)\n",
    "    # blob = cv2.dnn.blobFromImage(img, 1/255., (416, 416), swapRB=True)\n",
    "    # blob = cv2.dnn.blobFromImage(img, 1/255., (608, 608), swapRB=True)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers) \n",
    "\n",
    "    # outs[0].shape=(507, 85), 13*13*3=507\n",
    "    # outs[1].shape=(2028, 85), 26*26*3=2028\n",
    "    # outs[2].shape=(8112, 85), 52*52*3=8112\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            # detection: 4(bounding box) + 1(objectness_score) + 80(class confidence)\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > confThreshold:\n",
    "                # 바운딩 박스 중심 좌표 & 박스 크기\n",
    "                cx = int(detection[0] * w)\n",
    "                cy = int(detection[1] * h)\n",
    "                bw = int(detection[2] * w)\n",
    "                bh = int(detection[3] * h)\n",
    "\n",
    "                # 바운딩 박스 좌상단 좌표\n",
    "                sx = int(cx - bw / 2)\n",
    "                sy = int(cy - bh / 2)\n",
    "\n",
    "                boxes.append([sx, sy, bw, bh])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(int(class_id))\n",
    "\n",
    "    # 비최대 억제, Non Max Suppression\n",
    "# https://deep-learning-study.tistory.com/403\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "\n",
    "    for i in indices:\n",
    "#         i = i[0]\n",
    "        sx, sy, bw, bh = boxes[i]\n",
    "        label = f'{classes[class_ids[i]]}: {confidences[i]:.2}'\n",
    "        # color = colors[class_ids[i]]\n",
    "        color = (0, 0, 255)\n",
    "        cv2.rectangle(img, (sx, sy, bw, bh), color, 2)\n",
    "        cv2.putText(img, label, (sx, sy - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey() \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu_py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
